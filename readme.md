## Reference

* [A Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/?fbclid=IwAR04HRMsK-KyEJ8XsQO7TABIf_yywmDhTEuZRxRMLhpYrn99XEwphYn7teI)
  *  [pdf](pdf/A_recipe_for_Training_NN.pdf) 

## Top kagglers

* [limerobot](https://medium.com/kaggle-blog/zero-to-grandmaster-in-a-year-a-winners-interview-with-limerobot-18ddb3a1aae1)
* [Bestfitting](https://medium.com/kaggle-blog/profiling-top-kagglers-bestfitting-currently-1-in-the-world-58cc0e187b)
  * [pdf](./pdf/Bestfitting.pdf)



## Kaggle discussions

* [riid](https://www.kaggle.com/c/riiid-test-answer-prediction/discussion/210113)
* [data-science-bowl-2019](https://www.kaggle.com/c/data-science-bowl-2019/discussion/127891)



## Paper Review

* [XLNet: Generalized Autoregressive Pretraining for Language Understanding](./pdf/XLNet.pdf)
* [On the Variance of the Adaptive Learning Rate and Beyond](./pdf/RAdam)

*  [Evolved Transformer](pdf/Evolved_Transformer.pdf) 
*  [Cardiologist-Level_ Arrhythmia_ Detection_with_Convolutional_Neural_Networks](pdf/Cardiologist-Level_ Arrhythmia_ Detection_with_Convolutional_Neural_Networks.pdf) 

*  [Domain Adaptation](pdf/Domain_Adaptation.pdf) 
* [Language Models are Unsupervised Multitask Learners](./pdf/gpt2.pdf)
*  [Variants of Transformer](pdf/Variants_of_Transformer.pdf) 

